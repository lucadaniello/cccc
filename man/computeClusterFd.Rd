% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/computeClusterFd.R
\name{computeClusterFd}
\alias{computeClusterFd}
\title{Compute Smoothed Cluster Trajectories and Summary Information}
\usage{
computeClusterFd(data, final_part, opt, nx = 100)
}
\arguments{
\item{data}{A normalized data object, output of the \code{normalization()} function.}

\item{final_part}{A list returned by \code{extractBestPartition()}, containing the best partition and its index.}

\item{opt}{A list returned by \code{optimalSmoothing()}, containing optimal parameters: degree, penalty type, and lambda.}

\item{nx}{Integer. Number of interpolation points for evaluating smooth curves (default = 100).}
}
\value{
A list containing:
\describe{
\item{fd_obj}{Functional data object (\code{fd}) with relevant cluster-based attributes.}
\item{cluster_distribution}{Data frame with cluster sizes and relative percentages.}
\item{partition}{Integer vector with cluster assignment for each keyword.}
\item{rand_vec}{Numeric vector with similarity-to-center for each keyword curve.}
\item{keywords}{Character vector with keyword names.}
\item{traj_mean}{Matrix of unweighted cluster mean curves (rows = clusters, cols = time points).}
\item{traj_mean_rand}{Matrix of weighted cluster mean curves using the Rand vector.}
\item{rand_index}{Vector of average Rand Index for each cluster.}
\item{years}{Character vector of time points (years).}
}
}
\description{
This function computes a smoothed functional data object (\code{fd}) from the temporal keyword matrix,
using a B-spline basis and optimal smoothing parameters.
It also calculates within-cluster similarity measures (Rand vector), cluster-wise mean trajectories,
and returns all required information for downstream visualization and analysis.
}
\examples{
\dontrun{
tdm <- system.file("extdata", "tdm.csv", package = "cccc")
corpus <- system.file("extdata", "corpus.csv", package = "cccc")
data <- importData(tdm_file = tdm, corpus_file = corpus,
sep_tdm = ";",sep_corpus_info = ";",zone="stat")

data_nchi <- normalization(data, normty = "nchi", sc = 1000)
g <- runClusteringRange(data_nchi,
k_range = 2:26,
n_repeats = 20,
seed = 123,
dist_method = "euclidean",
verbose = TRUE)

results_m2 <- smoothingSelection(data_nchi, penalty_type = "m-2", plot = FALSE)
results_2  <- smoothingSelection(data_nchi, penalty_type = "2", plot = FALSE)
results_1  <- smoothingSelection(data_nchi, penalty_type = "1", plot = FALSE)
results_0  <- smoothingSelection(data_nchi, penalty_type = "0", plot = FALSE)

Compare and select best smoothing strategy
opt_res <- optimalSmoothing(list("m-2" = results_m2, "2" = results_2,
"1" = results_1, "0" = results_0))

g2 <- buildCIVf(clustering_set=g,
criteria_set = NULL,
min_valid_values = 0.75,
verbose = TRUE)

g3 <- selectBestPartitions(g2, g, graph=T)
rand_result <- computeRandMatrix(g3)

best_k <- selectBestKfromRand(rand_result)

final_part <- extractBestPartition(g3, best_k$best_k, rand_matrix=rand_result)

#' Compute Smoothed Cluster Trajectories and Summary Information
fd_obj <- computeClusterFd(data = data_nchi, final_part = final_part, opt = opt_res)
}


}
